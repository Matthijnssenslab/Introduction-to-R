---
title: "R introduction Nov 2023"
author: "Lander De Coninck"
output: 
  html_document:
    df_print: paged
    number_sections: TRUE
    pandoc_args: [
      "--number-offset=4"
    ]
    keep_md: no
    theme: default
    highlight: kate
    toc: true
    toc_depth: 3 
    toc_float:
       smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE}
library(tidyverse)
library(ggpubr)
library(car)
```
# Statistical analysis
## Comparing means

###  Between 2 groups (Student's t-test)
When to use?

- You have a categorical (defines the groups) and a continuous numeric variable (measurement of interest)
- You want to test if the mean of a population is significantly different from a specified value (one-sample t-test) or you want to test if the means of two populations are significantly different from each other (two-sample t-test)
- Your populations are normally distributed

```{r iris}
summary(iris)
```

```{r}
setosa <- iris %>% 
  filter(Species=="setosa")
head(setosa)
virginica <- iris %>% 
  filter(Species=="virginica")
head(virginica)
versicolor <- iris %>% 
  filter(Species=="versicolor")
head(versicolor)
```

Let's first create a dataframe with only 2 iris species and visualize the width of their sepals.
```{r}
rbind(setosa, virginica) %>% 
  ggplot(aes(x=Species, y=Sepal.Width, fill=Species))+
  geom_boxplot()
```

One of the assumptions of a t-test is that the data is normally distributed. Meaning that the data should be symmetric around the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. While visualizing, the normal distribution appears as a "bell curve". 
```{r}
rbind(setosa, virginica) %>% 
  ggplot(aes(x=Sepal.Width, fill=Species))+
  geom_histogram(binwidth = 0.08, alpha=0.8, position="identity") +
  geom_density(alpha=0.5)
```

Apart from visually checking if the data is normally distributed, a more robust method consists of testing the normality of the distribution with a statistical test. The Shapiro-Wilk test is suited for this, this test has as null hypothesis that the data is normally distributed.
```{r}
#Note: first calculate shapiro statistic only for setosa species, then introduce for loop
for (i in unique(iris$Species)){
  normality_test <- shapiro.test(iris$Sepal.Width[iris$Species==i])
  print(i)
  print(normality_test)
}
```

A second assumption that should be fulfilled before using a t-test is that the variances of the two groups are equal. The variance tells you something about the spread in your data, so how for each number in the dataset is from the mean. The F-test is used to test for equal variances. The null hypothesis of this test is that the variances between the two groups are equal.
```{r}
#Note: extract p-value separately
#Note2: test Sepal.Length
variance_test <- rbind(setosa, virginica) %>% 
  var.test(Sepal.Width ~ Species, data=.)
variance_test$p.value
```

Finally, if all assumptions are met, perform the t-test. The t-test's null hypothesis assumes that the means of the two groups are equal. If the p-value is < 0.05, the difference is statistically significant and it is very unlikely that we see this difference by chance. 
```{r}
#Note: extract p-value separately
#Note2: show t.test without equal variance
t_test <- t.test(virginica$Sepal.Width, 
       setosa$Sepal.Width, 
       var.equal = T)
t_test$p.value
```

Let's add this p-value to our boxplot with the `stat_compare_means` function of the `ggpubr` package.
```{r}
rbind(setosa, virginica) %>% 
  ggplot(aes(x=Species, y=Sepal.Width, fill=Species))+
  geom_boxplot()+
  ggpubr::stat_compare_means(method = "t.test", label.y=4.5, method.args = list(var.equal=T))
```

One sample t-test (test if the mean is significantly different from a specified value):
```{r}
t.test(setosa$Sepal.Width, mu=3, alternative = "greater")
```
### Non-parametric tests for comparing means between two groups (Wilcoxon)
When to use?

  - You have a categorical (defines the groups) and a continuous numeric variable (measurement of interest)
  - You want to test if the mean of a population is significantly different from a specified value (one-sample t-test) or you want to test if the means of two populations are significantly different from each other (two-sample t-test)
  - Your populations are NOT normally distributed
  
Let's test the normality of the `Petal.Width` variable for again the setosa and virginica species.
```{r}
shapiro.test(setosa$Petal.Width)
shapiro.test(virginica$Petal.Width)
```
The setosa's petal widths are not normally distributed, this means that we can not use the t-test. Therefore, we can use a non-parametric equivalent of the t-test, i.e. the Wilcoxon rank sum test. 
```{r}
wilcox <- wilcox.test(virginica$Petal.Width, 
       setosa$Petal.Width, alternative = "two.sided")
wilcox$p.value
```

### Comparing the means between multiple groups (ANOVA)
When to use?

  - You have a categorical variable with 3 or more variables and a continuous numeric variable (measurement of interest)
  - You want to test if the mean of the populations is significantly different from each other
  - Your populations are normally distributed and there is homogeneity of variance (the variance among the groups should be approximately equal)

```{r}
#Normally distributed
bartlett.test(Sepal.Width ~ Species, data=iris)
#Not normally distributed:
leveneTest(Sepal.Width ~ Species, data=iris)
```
One-way ANOVA compares the means between multiple groups and tells you if they are significantly different. ANOVA does not tell you which comparisons are different!

```{r}
anova <- aov(Sepal.Width ~ Species, data = iris)
summary(anova)
```
```{r}
iris %>% 
  ggplot(aes(x=Species, y=Sepal.Width, fill=Species))+
  geom_boxplot()+
  ggpubr::stat_compare_means(label.y=4.5, method = "aov")
```

When the ANOVA is statistically significant, you can proceed to test which groups are significantly different. To test which means are different across the groups, we have to perform multiple t-tests.
Exercise: Perform a t-test for each comparison of the Sepal.Width measurement and store each p-value in a separate variable.
```{r}
#Solution
setosa_versicolor <- t.test(setosa$Sepal.Width, versicolor$Sepal.Width)
setosa_virginica <- t.test(setosa$Sepal.Width, virginica$Sepal.Width)
versicolor_virginica <- t.test(versicolor$Sepal.Width, virginica$Sepal.Width)

pval1 <- setosa_versicolor$p.value
pval2 <- setosa_virginica$p.value
pval3 <- versicolor_virginica$p.value

comp1 <- t.test(iris[iris$Species == "setosa",]$Sepal.Width,
       iris[iris$Species=="virginica",]$Sepal.Width,)
comp2 <- t.test(iris[iris$Species == "setosa",]$Sepal.Width,
       iris[iris$Species=="versicolor",]$Sepal.Width,)
comp3 <- t.test(iris[iris$Species == "virginica",]$Sepal.Width,
       iris[iris$Species=="versicolor",]$Sepal.Width,)

pval1 <- comp1$p.value
pval2 <- comp2$p.value
pval3 <- comp3$p.value

#Solution2
stat.test <- iris %>%
  pivot_longer(-Species, names_to = "Measurement", values_to = "value") %>% 
  filter(Measurement=="Sepal.Width") %>% 
  rstatix::t_test(value ~ Species) %>%
  rstatix::adjust_pvalue(method = "BH") %>%
  rstatix::add_significance()
stat.test
```

NOTE: the non-parametric equivalent for the ANOVA test is the Kruskal-Wallis test.
```{r}
kruskal.test(Petal.Width ~ Species, data=iris)
```

### Correction for multiple testing
When doing multiple statistical tests, the probability to make a type I error (falsely rejecting the null hypothesis) increases. Therefore, we need to correct the p-values for multiple testing. The most simple but quite stringent correction is the Bonferroni correction. This correction divides the significance level alpha by the number of tests. 
Another correction for multiple testing is through the false discovery rate (FDR).  The FDR is the rate that differences called significant are truly null (so in reality not different). An FDR of 5% means that, among all the differences called significant, 5% of these are truly not different. An example is the Benjamini-Hochberg FDR.
```{r}
p_values <- c(pval1, pval2, pval3)
p_values
p.adjust(p_values, method = "bonferroni")
p.adjust(p_values, method = "BH")
```

The `ggpubr` package provides the `stat_pwc` function to easily visualize the significance across all comparisons.
```{r}
iris %>% 
  ggplot(aes(x=Species, y=Sepal.Width, fill=Species))+
  geom_boxplot()+
  ggpubr::stat_pwc(aes(x=Species, y=Sepal.Width, group=Species), 
                   method = "t.test", p.adjust.method="BH", label = "p.adj")
```

## Linear regression and correlation tests
When to use?

  - You have two numeric variables
  - You want to know if there is a linear correlation between these variables
  
```{r}
iris %>% 
  ggplot(aes(x=Petal.Width, y=Petal.Length))+
  geom_point()
```

### Correlation test
To calculate the correlation between two variables, we can use the `cor` function. This will output the correlation coefficient which can go from -1 to 1, with a value closer to 1 meaning that there is a strong correlation.
```{r}
cor(iris$Petal.Width, iris$Petal.Length)
```

### Linear regression model
We can fit a line through the data points, and the equation of this linear regression line is our model.
```{r}
model <- lm(Petal.Length ~ Petal.Width, iris) 
summary(model)
```

**Residuals**

Residuals are essentially the difference between the actual observed response values (here the petal length) and the response values that the model predicted.

<img src="https://www.math.net/img/a/probability-and-statistics/regression/residual/residual.png">

When assessing how well the model fit the data, you should look for a symmetrical (normal) distribution across these points on the mean value zero (0).

```{r}
hist(model$residuals)
shapiro.test(model$residuals)
```

**Estimate**

The coefficient intercept, in our example is the length of the petal if the width of the petal would be 0 cm.

Hypothetically, this would mean that a petal that is 0 cm wide, has a length of 1.1 cm. Of course, this does not make much sense in the real world because leafs with a width of 0 cm would be non-existent.

The second row in the Coefficients is the slope, or in our example, the effect that the petal width has on the its length. The slope term in our model is saying that for every cm of leaf width, the length increases with 2.2 cm.

**Pr (>t)**

The Pr(>t) is the p-value. A small p-value indicates that it is unlikely we will observe a relationship between the predictor (petal width) and response (petal length) variables due to chance.

Consequently, a small p-value for the intercept and the slope indicates that we can reject the null hypothesis which allows us to conclude that there is a relationship between the petal width and the petal length.

```{r}
iris %>% 
  ggplot(aes(x=Petal.Width, y=Petal.Length))+
  geom_point()+
  geom_smooth(method = "lm")+
  ggpubr::stat_cor(label.y = 6.5)+
  ggpubr::stat_regline_equation(label.y=6)
```

Exercise: Do a linear regresion analyis on the R `cars` dataset. This dataset contains data on the stopping distance of cars that are travelling at different speeds.
```{r}
#Solution:
mod <- lm(dist ~ speed, data=cars)
summary(mod)
hist(mod$residuals)
shapiro.test(mod$residuals)

cars %>% 
  ggplot(aes(x=speed, y=dist))+
  geom_point()+
  geom_smooth(method="lm")+
  stat_cor()+
  stat_regline_equation(label.y = 100)
```

